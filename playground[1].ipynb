{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(\"chromedriver_win64\\chromedriver.exe\")\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--allow-running-insecure-content')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "usr = os.getenv(\"USR\")\n",
    "pswd = os.getenv(\"PSWD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "[SUCCESS]: Logged into the website. \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "login_page = \"https://www.instagram.com/accounts/login/\"\n",
    "driver.get(login_page)\n",
    "time.sleep(4)\n",
    "\n",
    "# Accept the website cookies\n",
    "# driver.find_element(By.XPATH, \"/html/body/div[4]/div/div/button[1]\").click()\n",
    "# time.sleep(3)\n",
    "\n",
    "# Login with a random account since we can't scrap stories without being logged\n",
    "driver.find_element(By.NAME, \"username\").send_keys(usr)\n",
    "driver.find_element(By.NAME, \"password\").send_keys(pswd)\n",
    "\n",
    "# Click the login button\n",
    "driver.find_element(By.XPATH, '//*[@id=\"loginForm\"]/div/div[3]/button/div').click()\n",
    "print(colored(\"\\n[SUCCESS]: Logged into the website. \\n\", \"green\"))\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'movieseriesquotess'\n",
    "# username = 'realmadrid'\n",
    "# story_link = \"https://www.instagram.com/stories/{}/\".format(username)\n",
    "\n",
    "# # Get access to the story link\n",
    "# driver.get(story_link)\n",
    "# time.sleep(1)\n",
    "\n",
    "# rows = []\n",
    "# print(colored(\"\\n[SUCCESS]: Got into the story link. \\n\", \"green\"))\n",
    "# buttons = driver.find_elements(By.CSS_SELECTOR, 'div[role=\"button\"]')\n",
    "# for button in buttons:\n",
    "#     if button.get_attribute('innerHTML') == 'View story':\n",
    "#         button.click()\n",
    "#         break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while driver.current_url != \"https://www.instagram.com/\":\n",
    "#     # Collect the link to the video content of the story if it exists, otherwise take the image link\n",
    "    \n",
    "#     is_video = False\n",
    "#     try:\n",
    "#         content_element = driver.find_element(By.XPATH, '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/section/div[1]/div/div/div[1]/div[2]/div[1]/div/img')\n",
    "#         content_link = content_element.get_attribute('src')\n",
    "        \n",
    "#     except:\n",
    "#         is_video = True\n",
    "#         probable_elements = driver.find_elements(By.CSS_SELECTOR, 'video')\n",
    "#         for element in probable_elements:\n",
    "#             print(element.get_attribute('innerHTML'))\n",
    "#         content_link = probable_elements[0].get_attribute('src')\n",
    "        \n",
    "#     print(colored(f\"\\n[SUCCESS]: Got the content link:\\n\\t{content_link}. \\n\", \"green\"))\n",
    "\n",
    "#     # Get the link of the story\n",
    "#     insta_link = driver.current_url\n",
    "\n",
    "#     # Get the date of the story\n",
    "#     date = driver.find_element(By.XPATH, '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/section/div[1]/div/div/div[1]/div[1]/div[2]/div[1]/div/div/div/div/span/time') \\\n",
    "#                     .get_attribute(\"datetime\")\n",
    "\n",
    "#     # Append all collected information into a row\n",
    "#     rows.append(\n",
    "#         {\n",
    "#             'Instagram URL': insta_link,\n",
    "#             'Content URL': content_link,\n",
    "#             'Date': date,\n",
    "#             'is_video': is_video\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     # Click on the next button\n",
    "#     try:\n",
    "#         buttons = driver.find_elements(By.CSS_SELECTOR, 'div[role=\"button\"]')\n",
    "#         for button in buttons:\n",
    "#             if button.get_attribute('innerHTML').find('Next') != -1:\n",
    "#                 button.click()\n",
    "#                 break\n",
    "#     except:\n",
    "#         break\n",
    "\n",
    "#     time.sleep(1)\n",
    "    \n",
    "# # Save scrapped data into a dataframe\n",
    "# df = pd.DataFrame(rows)\n",
    "# tmp = os.path.join(\"collected_data\", \"pickles\")\n",
    "# if not os.path.exists(tmp): os.makedirs(tmp)\n",
    "# df.to_pickle(os.path.join(tmp, \"stories_{}.pkl\".format(username)))\n",
    "# # driver.quit()\n",
    "# print(colored(\"\\n[SUCCESS]: Scrapped all stories for the last 24h. \\n\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape information of the user\n",
    "user_link = f'https://www.instagram.com/{username}/'\n",
    "driver.get(user_link)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.join(\"collected_data\", \"info\")\n",
    "if not os.path.exists(dir): os.makedirs(dir)\n",
    "f = open(os.path.join(dir, f\"{username}_info.txt\"), \"w\")\n",
    "\n",
    "# info_list = driver.find_elements(By.XPATH, \\\n",
    "#     '//*[@id=\"mount_0_0_HU\"]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/ul/li')\n",
    "# for info in info_list:\n",
    "#     f.write(info.text + \"\\n\")\n",
    "# f.write(\"\\n\")\n",
    "num_posts = driver.find_element(By.XPATH, \\\n",
    "    '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/ul/li[1]/span/span').text\n",
    "num_followers = driver.find_element(By.XPATH, \\\n",
    "    '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/ul/li[2]/a/span/span').text\n",
    "num_following = driver.find_element(By.XPATH, \\\n",
    "    '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/ul/li[2]/a/span/span').text\n",
    "f.write('Number of posts: ' + num_posts + \"\\n\")\n",
    "f.write('Number of followers: ' + num_followers + \"\\n\")\n",
    "f.write('Number of following: ' + num_following + \"\\n\\n\")\n",
    "    \n",
    "bio = driver.find_element(By.XPATH, \\\n",
    "    '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/div[3]/h1').text\n",
    "f.write('Bio: ' + bio + \"\\n\\n\")\n",
    "\n",
    "try:\n",
    "    threads_username = driver.find_element(By.XPATH, \\\n",
    "        '//*[@id=\"mount_0_0_Pa\"]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/div[3]/div[2]/a/span/span').text\n",
    "    f.write('Threads username: ' + threads_username + \"\\n\")\n",
    "except NoSuchElementException:\n",
    "    f.write(\"No threads username\\n\")\n",
    "    \n",
    "try:\n",
    "    ext_link = driver.find_element(By.XPATH, '//*[@id=\"mount_0_0_Pa\"]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/div[3]/div[3]/a/span/span').text\n",
    "    f.write('External link: ' + ext_link + \"\\n\")\n",
    "except NoSuchElementException:\n",
    "    f.write(\"No external link\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in rows:\n",
    "#     content_link = row['Content URL']\n",
    "#     filename = f\"{uuid.uuid4()}.jpg\"\n",
    "#     dir = os.path.join(\"collected_data\", username)\n",
    "#     if not os.path.exists(dir): os.makedirs(dir)\n",
    "#     try:\n",
    "#         urllib.request.urlretrieve(content_link, os.path.join(dir, filename))\n",
    "#         print(colored(f\"\\n[SUCCESS]: Downloaded the content link:\\n\\t{content_link}. \\n\", \"green\"))\n",
    "#         print(colored(f\"\\n[SUCCESS]: Saved the content to the file:\\n\\t{filename}. \\n\", \"green\"))\n",
    "#     except Exception as e:\n",
    "#         print(colored(f\"\\n[ERROR]: Couldn't download the content link:\\n\\t{content_link}. \\n\", \"red\"))\n",
    "#         print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
